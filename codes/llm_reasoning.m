function S = llm_reasoning(data_fb, user_fb, varargin)
% LLM_INFERRING  Get initial priors from an LLM (returns struct S and raw text).

if nargin < 2 || isempty(user_fb)
    user_fb = "No subjective feedback was provided by the user.";
end

% ---- Parse options
p = inputParser;
addParameter(p,'ModelName',"gpt-4o-mini");
addParameter(p,'Temperature',0.0);
addParameter(p,'MaxNumTokens',300);
addParameter(p,'UseAddon',true);
parse(p,varargin{:});
opt = p.Results;

sysprompt = "You are an expert assigning reasonable initial guesses for parameters in an adaptive lane-keeping controller to ensure safety and efficiency.\n\n";
% fmt = ...
%     "=== Quantitative feedback from the last run ===\n%s\n\n" + ...
%     "=== User feedback ===\n%s\n\n" + ...
%     "=== Your task ===\n" + ...
%     "Based on both quantitative feedback and qualitative user feedback, infer new reasonable parameters." + ...
%     "Return STRICT JSON with keys: e_max, mu_0, sigma_0, bar_sigma, assumptions, rationale.\n" + ...
%     " Meanings:" + ...
%     " - e_max: maximum lane tracking error tolerance. Larger for more aggressive turns/risk; smaller for more conservative/precise." + ...
%     " - mu_0: initial prior for road–tire friction (icy small, normal medium, dry large)." + ...
%     " - sigma_0: uncertainty (std^2) of the friction prior; larger if the user sounds unsure or contradictory." + ...
%     " - bar_sigma: confidence of the estimator on its measurements; increase if not sure if estimator is good. You should try to trust the estimator." + ...
%     " Policy:" + ...
%     " - If the user uses vague words (""seems"", ""maybe"", ""not sure"", ""probably""), pick the most likely road class they stated," + ...
%     " - Only change e_max with explicit user cues." + ...
%     " Valid discrete ranges:" + ...
%     " - e_max ∈ {3,5,10}; mu_0 ∈ {0.3,0.5,0.9}; sigma_0 ∈ {0.05,0.3}; bar_sigma ∈ {0.05,0.3}." + ...
%     " - Keep bar_sigma=0.05. Only set bar_sigma=0.3 if the text explicitly mentions sensing/visibility problems (fog/rain/snow/glare/low light/sensor fault) and explain why.\n" + ...
%     " - Keep sigma_0=0.05 and align mu_0 with previous estimation. Set sigma_0=0.3 and different mu_0 only if (a) the user hedges about the ROAD (""seems/maybe/not sure/probably""), or (b) the user statement contradicts quantitative feedback suggesting a different friction class; explain the uncertainty.\n" + ...
%     " Output ONLY JSON in this exact shape: " + ...
%     " {""e_max"":0,""mu_0"":0.0,""sigma_0"":0.0,""bar_sigma"":0.0,""assumptions"":{""style"":"""",""road"":"""",""speed_kmh"":0,""lane_quality"":""""},""rationale"":""""} " + ...
%     "Ensure values are from the allowed sets and remember these are initial priors, not ground truth.\n";


fmt = ...
    "=== Quantitative feedback from the last run ===\n%s\n\n" + ...
    "=== User feedback ===\n%s\n\n" + ...
    "=== Your task ===\n" + ...
    "Based on both quantitative feedback and qualitative user feedback, infer new reasonable parameters." + ...
    " Return STRICT JSON with keys: e_max, mu_0, sigma_0, bar_sigma, init_v, assumptions, rationale.\n" + ...
    " Meanings:" + ...
    " - e_max: maximum lane tracking error tolerance. Larger for more aggressive turns/risk; smaller for more conservative/precise." + ...
    " - mu_0: initial prior for road–tire friction (icy small, normal medium, dry large)." + ...
    " - sigma_0: uncertainty (std^2) of the friction prior; larger if the user sounds unsure or contradictory." + ...
    " - bar_sigma: confidence of the estimator on its measurements; increase if not sure if estimator is good. You should try to trust the estimator." + ...
    " - init_v: initial velocity of the vehicle. large for aggressive, small for conservative." + ...    
    " Policy:" + ...
    " - If the user uses vague words (""seems"", ""maybe"", ""not sure"", ""probably""), pick the most likely road class they stated," + ...
    " - Only change e_max with explicit user cues." + ...
    " Valid discrete ranges:" + ...
    " - e_max ∈ {3,5,10}; mu_0 ∈ {0.3,0.5,0.9}; sigma_0 ∈ {0.05,0.3}; bar_sigma ∈ {0.05,0.3}." + ...
    " - Keep bar_sigma=0.05. Only set bar_sigma=0.3 if the text explicitly mentions sensing/visibility problems (fog/rain/snow/glare/low light/sensor fault) and explain why.\n" + ...
    " - e_max ∈ {3,5,10}; mu_0 ∈ {0.3,0.5,0.9}; sigma_0 ∈ {0.05,0.3}; bar_sigma ∈ {0.05,0.3}; init_v ∈ {10,20}." + ...
    " Output ONLY JSON in this exact shape: " + ...
    " {""e_max"":0,""mu_0"":0.0,""sigma_0"":0.0,""bar_sigma"":0.0,""init_v"":0,""assumptions"":{""style"":"""",""road"":"""",""speed_kmh"":0,""lane_quality"":""""},""rationale"":""""} " + ...
    "Ensure values are from the allowed sets and remember these are initial priors, not ground truth.\n";


prompt = sprintf(fmt, data_fb, user_fb);

if contains(p.Results.ModelName, "gpt", "IgnoreCase", true)

% with Large Language Models (LLMs) with MATLAB add-on
fprintf("working with "+ p.Results.ModelName);
model = openAIChat(sysprompt,ModelName=p.Results.ModelName);
resp = generate(model, prompt, Temperature=0.2, MaxNumTokens=300);

elseif contains(p.Results.ModelName, "gemini", "IgnoreCase", true)
    fprintf("working with "+ p.Results.ModelName)
    apiKey = getenv('X-goog-api-key');
    url = "https://generativelanguage.googleapis.com/v1beta/models/" + p.Results.ModelName + ":generateContent";
    fullUrl = url + "?key=" + apiKey;

    body = struct( ...
        "contents", [ ...
            struct("role", "user", "parts", struct("text", sysprompt)), ...
            struct("role", "user", "parts", struct("text", prompt)) ...
        ], ...
        "generationConfig", struct( ...
            "temperature", 0.2, ...
            "maxOutputTokens", 8192, ...
            "candidateCount", 1, ...
            "response_mime_type", "application/json" ...  % <-- crucial line
        ) ...
    );

    opts = weboptions( ...
        "HeaderFields", {'x-goog-api-key' apiKey}, ...
        "MediaType","application/json", ...
        "Timeout",60 ...
    );

    % === Call Gemini ===
    resp = webwrite(fullUrl, body, opts);

    % === Parse returned JSON ===
    resp = resp.candidates(1).content.parts(1).text;

elseif contains(p.Results.ModelName, "deepseek", "IgnoreCase", true)
    fprintf("working with "+ p.Results.ModelName + "\n")
    apiKey = getenv('deepseekApiKey');
    apiUrl = 'https://api.deepseek.com/v1/chat/completions';
    
    % Prepare the request headers
    headers = {'Authorization', ['Bearer ' apiKey]; ...
               'Content-Type', 'application/json'};

    % Prepare the messages with system prompt and user prompt
    messages = [
        struct('role', 'system', 'content', sysprompt);
        struct('role', 'user', 'content', prompt)
    ];
    
    % Create request body
    requestBody = struct(...
        'model', p.Results.ModelName, ...
        'messages', {messages}, ...
        'max_tokens', 4096, ...
        'temperature', 0.7 ... 
    );

    
    % Convert to JSON
    jsonBody = jsonencode(requestBody);
    
    % Make API call
    options = weboptions(...
        'RequestMethod', 'POST', ...
        'HeaderFields', headers, ...
        'MediaType', 'application/json', ...
        'Timeout', 60 ...
    );

    apiResponse = webwrite(apiUrl, jsonBody, options);
    resp = apiResponse.choices(1).message.content;
else
    error("Unknown model name: %s", p.Results.ModelName);
end

% % without add-on
% url  = "https://api.openai.com/v1/responses";
% opts = weboptions( ...
%     "HeaderFields", {'Authorization',['Bearer ' char(apiKey)]}, ...
%     "MediaType","application/json", ...
%     "Timeout",60);
% 
% 
% body = struct( ...
%     "model","gpt-4o-mini", ...
%     "input",sysprompt + prompt ...
% );
% 
% resp = webwrite(url, body, opts);
% resp = resp.output.content.text;

% display result                    
resp = regexprep(resp, '```[a-zA-Z]*', '');  % remove ```json, ```JSON, etc.
resp = strrep(resp, '```', '');              % remove closing ```
resp = strtrim(resp);
expr = '{.*}';
match = regexp(resp, expr, 'match');
if ~isempty(match)
    resp = match{1};
end
S = jsondecode(resp);
end